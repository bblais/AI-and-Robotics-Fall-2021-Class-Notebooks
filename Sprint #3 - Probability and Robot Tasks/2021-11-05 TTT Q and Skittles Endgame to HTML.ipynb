{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d315de-d356-4277-bfcd-b3c953d044e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  0.2.34\n"
     ]
    }
   ],
   "source": [
    "from Game import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bcbd9-2ffa-42ac-8584-47e3d2d29d0a",
   "metadata": {},
   "source": [
    "## Game functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15420972-b911-4f92-9727-3791e0021b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state():\n",
    "    state=Board(3,3)\n",
    "    state.pieces=[\".\",\"X\",\"O\"]\n",
    "    \n",
    "    state[0]=state[3]=1\n",
    "    state[1]=state[4]=2\n",
    "    return state\n",
    "\n",
    "def show_state(state):\n",
    "    print(state)\n",
    "    \n",
    "def valid_moves(state,player):\n",
    "    # run through all the spots\n",
    "    # if it is empty, then append that\n",
    "    # location to the possible moves\n",
    "    \n",
    "    moves=[]\n",
    "    for location in range(9):\n",
    "        if state[location]==0:\n",
    "            moves.append(location)\n",
    "            \n",
    "    return moves  \n",
    "\n",
    "def update_state(state,player,move):\n",
    "    new_state=state\n",
    "    \n",
    "    new_state[move]=player\n",
    "    return new_state    \n",
    "    \n",
    "def win_status(state,player):\n",
    "    # the state is *after* the move for the player\n",
    "\n",
    "    #  0  1  2 \n",
    "    #  3  4  5 \n",
    "    #  6  7  8   \n",
    "    \n",
    "    for start,middle,end in [\n",
    "        [0,1,2],[3,4,5],[6,7,8],\n",
    "        [0,3,6],[1,4,7],[2,5,8],\n",
    "        [0,4,8],[2,4,6],\n",
    "                ]:\n",
    "        \n",
    "        if state[start]==player and state[middle]==player and state[end]==player:\n",
    "            return \"win\"\n",
    "        \n",
    "    if player==1:\n",
    "        other_player=2\n",
    "    else:\n",
    "        other_player=1\n",
    "    \n",
    "    if not valid_moves(state,other_player):\n",
    "        return \"stalemate\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73f5f6-e774-4bde-94f3-db57480a8de9",
   "metadata": {},
   "source": [
    "## Agent Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc2bb6e-04ec-49b8-b665-cc6c7a0d8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_move(state,player):\n",
    "    \n",
    "    state.show_locations()\n",
    "    print(\"Player\",player)\n",
    "    move=int(input(\"which square to move?\"))\n",
    "    return move\n",
    "\n",
    "human_agent=Agent(human_move)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84dda3ca-ea87-440f-a9fa-bbb5ead27e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_move(state,player):\n",
    "    \n",
    "    move=random.choice(valid_moves(state,player))\n",
    "    return move\n",
    "\n",
    "\n",
    "random_agent=Agent(random_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74454473-403a-4597-ada4-edd245cb5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Game.minimax import *\n",
    "def minimax_move(state,player):\n",
    "\n",
    "    values,moves=minimax_values(state,player,display=False)\n",
    "    return top_choice(moves,values)\n",
    "\n",
    "\n",
    "minimax_agent=Agent(minimax_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f47303-f2ca-45e2-973f-e4254478ac98",
   "metadata": {},
   "source": [
    "## Skittles Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213ef3b2-ca15-4ba0-ae39-13b63adaab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skittles_move(state,player,info):\n",
    "    T=info.T\n",
    "    last_state=info.last_state\n",
    "    last_action=info.last_action\n",
    "    learning=info.learning\n",
    "    \n",
    "    if state not in T:\n",
    "        actions=valid_moves(state,player)\n",
    "        T[state]=Table()\n",
    "        for action in actions:\n",
    "            T[state][action]=2  # initial number of skittles\n",
    "    \n",
    "    move=weighted_choice(T[state])\n",
    "    status=None\n",
    "    \n",
    "    if move is None:  \n",
    "        \n",
    "        is_random_move=True\n",
    "        move=random_move(state,player)\n",
    "        \n",
    "        if learning:  # don't save for test cases\n",
    "            info.saved.append( \n",
    "                [deepcopy(T),deepcopy(last_state),deepcopy(last_action),deepcopy(state),is_random_move,move,None,status]\n",
    "                )\n",
    "        \n",
    "        \n",
    "        # learn\n",
    "        if learning:\n",
    "            if last_state:\n",
    "                T[last_state][last_action]-=1 # take away a skittle\n",
    "                if T[last_state][last_action]<0:\n",
    "                    T[last_state][last_action]=0\n",
    "    \n",
    "        return move\n",
    "    else:\n",
    "        \n",
    "        if learning:  # don't save for test cases\n",
    "            info.saved.append( \n",
    "                [deepcopy(T),deepcopy(last_state),deepcopy(last_action),deepcopy(state),is_random_move,move,None,status]\n",
    "                )        \n",
    "        \n",
    "        \n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb63acf-7843-447e-8ba1-2d97f3d22690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skittles_after(status,player,info):\n",
    "    # not return anything but...\n",
    "    # will adjust the skittles table if lost the game\n",
    "    T=info.T\n",
    "    last_state=info.last_state\n",
    "    last_action=info.last_action\n",
    "    learning=info.learning\n",
    "    \n",
    "    if learning:  # don't save for test cases\n",
    "        info.saved.append( \n",
    "            [deepcopy(T),deepcopy(last_state),deepcopy(last_action),None,False,None,None,status]\n",
    "            )        \n",
    "    \n",
    "    \n",
    "    if learning:\n",
    "        if status=='lose':  # only learn when you lose\n",
    "            T[last_state][last_action]-=1 # take away a skittle\n",
    "            if T[last_state][last_action]<0:\n",
    "                T[last_state][last_action]=0\n",
    "                \n",
    "    if learning:  # don't save for test cases\n",
    "        info.saved.append( \n",
    "            [deepcopy(T),deepcopy(last_state),deepcopy(last_action),None,False,None,None,status]\n",
    "            )        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c67522-fbd6-4eb9-beca-71b88561edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "skittles1_agent=Agent(skittles_move)\n",
    "skittles1_agent.post=skittles_after\n",
    "skittles1_agent.T=Table()  # makes an empty table\n",
    "skittles1_agent.learning=True\n",
    "skittles1_agent.saved=[]\n",
    "\n",
    "skittles2_agent=Agent(skittles_move)\n",
    "skittles2_agent.post=skittles_after\n",
    "skittles2_agent.T=Table()  # makes an empty table\n",
    "skittles2_agent.learning=True\n",
    "skittles2_agent.saved=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fd7d77-1fcd-41f0-89f9-71faec7e5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fbee0a-e2a4-4946-848c-3416a4d9ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_move(state,player,info):\n",
    "    Q=info.Q\n",
    "    last_state=info.last_state\n",
    "    last_action=info.last_action\n",
    "    learning=info.learning\n",
    "    \n",
    "    \n",
    "    α=info.α  # learning rate\n",
    "    ϵ=info.ϵ  # how often to take a random move\n",
    "    γ=info.γ  # memory constant -- how quickly does the table update back in time (earlier in the game)\n",
    "    \n",
    "    if not learning:\n",
    "        α=0.0  # don't update the weights\n",
    "        ϵ=0.0  # don't do random moves when testing\n",
    "    \n",
    "    # \\alpha <hit tab>    α\n",
    "    # \\epsilon <hit tab>  ϵ\n",
    "    # \\gamma <hit tab>    γ\n",
    "    \n",
    "    if state not in Q:\n",
    "        actions=valid_moves(state,player)\n",
    "        Q[state]=Table()\n",
    "        for action in actions:\n",
    "            Q[state][action]=0  # initial value of table\n",
    "    \n",
    "    \n",
    "    is_random_move=False\n",
    "    if random.random()<ϵ:  # take a random move occasionally to explore the environment\n",
    "        move=random_move(state,player)\n",
    "        is_random_move=True\n",
    "        assert learning\n",
    "        \n",
    "    else:\n",
    "        move=top_choice(Q[state])\n",
    "    \n",
    "    \n",
    "    reward=0\n",
    "    status=None\n",
    "    if learning:  # don't save for test cases\n",
    "        info.saved.append( \n",
    "            [deepcopy(Q),deepcopy(last_state),deepcopy(last_action),deepcopy(state),is_random_move,move,reward,status]\n",
    "            )\n",
    "    \n",
    "    if not last_action is None:  # not the first move\n",
    "        Q[last_state][last_action]+=α*(reward +\n",
    "                    γ*max([Q[state][a] for a in Q[state]]) - Q[last_state][last_action])\n",
    "                    \n",
    "    \n",
    "    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffbfa94-e8c2-4d42-8ea8-9a7c462310a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_after(status,player,info):\n",
    "    Q=info.Q\n",
    "    last_state=info.last_state\n",
    "    last_action=info.last_action\n",
    "    learning=info.learning\n",
    "    \n",
    "    α=info.α  # learning rate\n",
    "    ϵ=info.ϵ  # how often to take a random move\n",
    "    γ=info.γ  # memory constant -- how quickly does the table update back in time (earlier in the game)\n",
    "    \n",
    "    # \\alpha <hit tab>    α\n",
    "    # \\epsilon <hit tab>  ϵ\n",
    "    # \\gamma <hit tab>    γ\n",
    "\n",
    "    if status=='lose':\n",
    "        reward=-1\n",
    "    elif status=='win':\n",
    "        reward=1\n",
    "    elif status=='stalemate':\n",
    "        reward=.5 # value stalemate a little closer to a win\n",
    "    else:\n",
    "        reward=0\n",
    "        \n",
    "    is_random_move=move=None        \n",
    "    \n",
    "    if learning:  # don't save for test cases\n",
    "        info.saved.append( \n",
    "            [deepcopy(Q),deepcopy(last_state),deepcopy(last_action),None,is_random_move,move,reward,status]\n",
    "            )\n",
    "    \n",
    "    if learning:\n",
    "        Q[last_state][last_action]+=α*(reward - Q[last_state][last_action])\n",
    "        \n",
    "    if learning:  # don't save for test cases\n",
    "        info.saved.append( \n",
    "            [deepcopy(Q),deepcopy(last_state),deepcopy(last_action),None,is_random_move,move,reward,status]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7239b4-59a3-41d1-b61e-bc55760d744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_agent=Agent(Q_move)\n",
    "Q1_agent.post=Q_after\n",
    "Q1_agent.Q=Table()  # makes an empty table\n",
    "Q1_agent.learning=True\n",
    "Q1_agent.saved=[]\n",
    "\n",
    "Q1_agent.α=0.3  # learning rate\n",
    "Q1_agent.ϵ=0.5  # how often to take a random move\n",
    "Q1_agent.γ=0.9  # memory constant -- how quickly does the table update back in time (earlier in the game)\n",
    "\n",
    "Q2_agent=Agent(Q_move)\n",
    "Q2_agent.post=Q_after\n",
    "Q2_agent.Q=Table()  # makes an empty table\n",
    "Q2_agent.learning=True\n",
    "Q1_agent.saved=[]\n",
    "\n",
    "Q2_agent.α=Q1_agent.α  # learning rate\n",
    "Q2_agent.ϵ=Q1_agent.ϵ  # how often to take a random move\n",
    "Q2_agent.γ=Q1_agent.γ  # memory constant -- how quickly does the table update back in time (earlier in the game)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887d351-f175-4af5-9b22-5687792cb8d6",
   "metadata": {},
   "source": [
    "## Running the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2645fa4b-8239-42fe-8eab-28eec2ddd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c75e203-1d29-4bf6-89d5-3a22a06a7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1=Q1_agent\n",
    "agent2=minimax_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a345f963-fb98-4731-9e8e-1a2a0f4fe9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train=1\n",
    "N_test=100\n",
    "number_of_epochs=50\n",
    "agent1_test=None\n",
    "agent2_test=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "492ad9ce-8c46-4689-a8b1-ee127d2790a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 23.15it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iteration_count=0\n",
    "percentage_won_player1=[]\n",
    "percentage_won_player2=[]\n",
    "percentage_tie=[]\n",
    "number_of_iterations=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    for i in tqdm(range(number_of_epochs)):\n",
    "\n",
    "        agent1.learning=True\n",
    "        agent2.learning=True\n",
    "\n",
    "        g=Game(number_of_games=N_train)\n",
    "        g.display=False\n",
    "        result=g.run(agent1,agent2)\n",
    "\n",
    "\n",
    "        if agent1_test is None:\n",
    "            agent1_test=agent1\n",
    "        if agent2_test is None:\n",
    "            agent2_test=agent2\n",
    "\n",
    "        # turn learning off to test\n",
    "        agent1.learning=False\n",
    "        agent2.learning=False\n",
    "\n",
    "        g=Game(number_of_games=N_test)\n",
    "        g.display=False\n",
    "        result=g.run(agent1_test,agent2_test)\n",
    "        iteration_count+=N_train\n",
    "\n",
    "        percentage_won_player1.append(result.count(1)/N_test*100)\n",
    "        percentage_won_player2.append(result.count(2)/N_test*100)\n",
    "        percentage_tie.append(result.count(0)/N_test*100)\n",
    "        number_of_iterations.append(iteration_count)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811845c1-c593-4948-9857-dee15493241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print(percentage_won_player1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef722bc-897c-46c7-bfc1-3482f2b1a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2, 0, 1, 2, 0, 0, 0, 0): {2: -0.9176457,\n",
       "  5: -0.081,\n",
       "  6: 0.9999678009424419,\n",
       "  7: 0.0,\n",
       "  8: -0.1377},\n",
       " (1, 2, 0, 1, 2, 0, 2, 0, 1): {2: -0.51, 5: -0.51, 7: -0.51},\n",
       " (1, 2, 0, 1, 2, 0, 2, 1, 0): {2: 0.0, 5: 0, 8: -0.51},\n",
       " (1, 2, 1, 1, 2, 0, 2, 1, 2): {5: 0.15},\n",
       " (1, 2, 0, 1, 2, 1, 2, 0, 0): {2: -0.51, 7: -0.3, 8: -0.3},\n",
       " (1, 2, 1, 1, 2, 2, 2, 1, 0): {8: 0.15}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_agent.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08a847-ac13-4e6a-b169-3b4287b139b1",
   "metadata": {},
   "source": [
    "## Export to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b35846e5-fe5f-463c-8dd6-c14189254be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2rowmap(Q,player=1):\n",
    "    states=list(Q.keys())\n",
    "    state_rowmap={}\n",
    "    if isinstance(states[0],int):   # use the state as a row\n",
    "        for state in states:\n",
    "            state_rowmap[state]=state\n",
    "            \n",
    "    else:    \n",
    "        for i,state in enumerate(Q):\n",
    "            state_rowmap[state]=i\n",
    "            \n",
    "    action_rowmap={}\n",
    "            \n",
    "    all_actions=[]\n",
    "    for i,state in enumerate(Q):\n",
    "        actions=valid_moves(state,player)\n",
    "        \n",
    "        if isinstance(actions[0],int):  # use action as column\n",
    "            for action in actions:\n",
    "                action_rowmap[action]=action\n",
    "                \n",
    "        else:\n",
    "            for action in actions:\n",
    "                if action in rowmap:\n",
    "                    continue\n",
    "                action_rowmap[action]=len(action_rowmap)\n",
    "            \n",
    "            \n",
    "    return state_rowmap,action_rowmap\n",
    "        \n",
    "    \n",
    "def state2str(state):\n",
    "    b=initial_state()\n",
    "    b.board=state\n",
    "    \n",
    "    s=str(b).rstrip()\n",
    "    \n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a14d3b7c-8873-47f0-bb85-32e78c588b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning2html(agent,player,filename):\n",
    "    from numpy import ones\n",
    "    from numpy import nan\n",
    "    from pandas import DataFrame\n",
    "    \n",
    "    if '.html' not in filename:\n",
    "        raise ValueError(f\"Needs to be an html file not '{filename}'\")\n",
    "        \n",
    "    try:\n",
    "        Q=agent.Q\n",
    "        table_name='Q'\n",
    "    except AttributeError:\n",
    "        Q=agent.T\n",
    "        table_name='T'\n",
    "        \n",
    "    state_rowmap,action_rowmap=state2rowmap(Q,player)\n",
    "    \n",
    "    action_row_indices=[action_rowmap[a] for a in action_rowmap]\n",
    "    all_possible_moves=list(range(max(action_row_indices)+1))\n",
    "    Qmat=nan*ones((len(agent.Q),len(all_possible_moves)))\n",
    "\n",
    "    \n",
    "    if table_name=='Q':\n",
    "        with open(filename,'w') as fid:\n",
    "\n",
    "            fid.write(\"<h1>State Rows</h1>\\n\")    \n",
    "\n",
    "            for state in Q1_agent.Q:\n",
    "                fid.write(\"<p><strong>Row %d:</strong></p>\\n\" % state_rowmap[state])\n",
    "                fid.write(f\"<pre>{state2str(state)}</pre>\\n\")\n",
    "\n",
    "            Qmat=nan*ones((len(Q1_agent.Q),len(all_possible_moves)))\n",
    "            df = DataFrame(Qmat, columns=all_possible_moves, index=range(len(Q1_agent.Q)))\n",
    "            df.index.name = \"State #\"\n",
    "            df.columns.name=\"Actions\"            \n",
    "\n",
    "            s=df.to_html()\n",
    "            fid.write(\"<p><strong>Q Table</strong></p>\\n\")    \n",
    "            fid.write(s)\n",
    "\n",
    "            fid.write(\"\\n<hr>\\n\")       \n",
    "\n",
    "            count=0\n",
    "            game=1\n",
    "\n",
    "            fid.write(f\"<p>{Q1_agent.ϵ*100:.2f} percent random moves.<p>\\n\")\n",
    "            for Q,last_state,last_action,state,is_random_move,move,reward,status in Q1_agent.saved:\n",
    "\n",
    "                if state is None:\n",
    "                    if flag:\n",
    "                        r_ls=state_rowmap[tuple(last_state)]\n",
    "                        r_la=action_rowmap[last_action]\n",
    "\n",
    "\n",
    "                        # Q[last_state][last_action]+=α*(reward - Q[last_state][last_action])\n",
    "\n",
    "                        fid.write(f\"<p>'{status}' Last State {r_ls} Last Action {r_la} Reward {reward}</p>\\n\")\n",
    "                        fid.write(f\"<p style='text-indent:40px'>Q[{r_ls}][{r_la}]=Q[{r_ls}][{r_la}]+{Q1_agent.α:.2f}*({reward} - Q[{r_ls}][{r_la}])</p>\")\n",
    "                        fid.write(f\"<p style='text-indent:50px'>       ={Q[last_state][last_action]:.2g} + {Q1_agent.α:.2f}*({reward}-{Q[last_state][last_action]:.2g})</p>\")\n",
    "                        fid.write(f\"<p style='text-indent:50px'>={Q[last_state][last_action] + Q1_agent.α*(reward -Q[last_state][last_action])}</p>\\n\")\n",
    "\n",
    "                        flag=False\n",
    "                    else:\n",
    "                        newQ=Q\n",
    "\n",
    "\n",
    "                        Qmat=nan*ones((len(Q1_agent.Q),len(all_possible_moves)))\n",
    "\n",
    "                        for state in Q:\n",
    "                            for action in Q[state]:\n",
    "                                r_s=state_rowmap[tuple(state)]\n",
    "                                r_m=action_rowmap[action]\n",
    "\n",
    "                                Qmat[r_s,r_m]=Q[state][action]\n",
    "\n",
    "                        df = DataFrame(Qmat, columns=all_possible_moves, index=range(len(Q1_agent.Q)))\n",
    "                        df.index.name = \"State #\"\n",
    "                        df.columns.name=\"Actions\"            \n",
    "\n",
    "                        s=df.to_html()\n",
    "                        fid.write(\"<p><strong>Q Table</strong></p>\\n\")    \n",
    "                        fid.write(s)\n",
    "                        fid.write(\"\\n<hr>\\n\")       \n",
    "\n",
    "\n",
    "\n",
    "                else:   \n",
    "                    flag=True\n",
    "\n",
    "                    if is_random_move:\n",
    "                        rm=\"(Random) \"\n",
    "                    else:\n",
    "                        rm=\"\"\n",
    "\n",
    "\n",
    "\n",
    "                    if last_state:\n",
    "                        r_ls=state_rowmap[tuple(last_state)]\n",
    "                        r_s=state_rowmap[tuple(state)]\n",
    "                        r_m=action_rowmap[move]\n",
    "                        r_la=action_rowmap[last_action]\n",
    "\n",
    "\n",
    "                        fid.write(f\"<p>Last State {r_ls} Last Action {r_la} State {r_s} {rm}Move {r_m} Reward {reward}</p>\\n\")\n",
    "\n",
    "            #                     Q[last_state][last_action]+=α*(reward +\n",
    "            #                     γ*max([Q[state][a] for a in Q[state]]) - Q[last_state][last_action])\n",
    "\n",
    "                        fid.write(f\"<p style='text-indent:40px'>Q[{r_ls}][{r_la}]=Q[{r_ls}][{r_la}]+{Q1_agent.α:.2f}*({reward} + {Q1_agent.γ:.2f}*(max(Q[{r_s}]: {[Q[state][a] for a in Q[state]]}) - Q[{r_ls}][{r_la}]))</p>\\n\")\n",
    "                        fid.write(f\"<p style='text-indent:50px'>={Q[last_state][last_action]:.2g} + {Q1_agent.α:.2f}*({reward} + {Q1_agent.γ:.2f}*({max([Q[state][a] for a in Q[state]])}-{Q[last_state][last_action]:.2g}))</p>\\n\")\n",
    "                        fid.write(f\"<p style='text-indent:50px'>={Q[last_state][last_action] + Q1_agent.α*(reward + Q1_agent.γ*(max([Q[state][a] for a in Q[state]])-Q[last_state][last_action]))}\")\n",
    "                    else:\n",
    "                        fid.write(\"<h1>Game %d</h1>\\n\" % game)\n",
    "                        game+=1\n",
    "\n",
    "                        fid.write(f\"<p>State {state_rowmap[tuple(state)]} {rm}Move {action_rowmap[move]}</p>\\n\")\n",
    "\n",
    "        print(f\"Saved {game} Games to {filename}.\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Skittles not implemented yet.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "478d3ad6-5493-4a47-8edb-c4f595167f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 51 Games to TTT Q Example.html.\n"
     ]
    }
   ],
   "source": [
    "learning2html(Q1_agent,1,'TTT Q Example.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d8614-8c9a-4d9d-96ac-0df00b144ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
